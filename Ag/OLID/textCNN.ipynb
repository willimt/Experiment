{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.legacy import data\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from d2l import torch as d2l\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "sys.path.append(\"D:/Experiment\")\n",
    "from tqdm import tqdm\n",
    "from MyKu import training\n",
    "from MyKu import processing\n",
    "from torchtext.vocab import Vectors\n",
    "from spacy.lang.en import English\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels, dropout, **kwargs):\n",
    "        super(textCNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.decoder = nn.Linear(sum(num_channels), 2)\n",
    "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(embed_size, c, k))\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.permute(1, 0)\n",
    "        embeddings = self.embedding(inputs)\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        encoding = torch.cat([torch.squeeze(self.relu(self.pool(conv(embeddings))), dim=-1) for conv in self.convs], dim=1)\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en = English()\n",
    "\n",
    "\n",
    "def tokenizer(text):  # create a tokenizer function\n",
    "    \"\"\"\n",
    "    定义分词操作\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "\n",
    "def DataLoader():\n",
    "    def tokenize(x): return x.split()\n",
    "\n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenizer,\n",
    "                      lower=True, include_lengths=True, fix_length=40)\n",
    "    LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "    # 假如train.csv文件并不是只有两列，比如1、3列是review和polarity，2列是我们不需要的数据，\n",
    "    # 那么就要添加一个全是None的元组， fields列表存储的Field的顺序必须和csv文件中每一列的顺序对应，\n",
    "\n",
    "    train_fields = [(None, None), ('tweet', TEXT), ('subtask_a', LABEL)]\n",
    "    # train_fields = [(None, None), (None, None), (None, None), (None, None), ('text', TEXT), ('task1', LABEL)]\n",
    "    train_data = data.TabularDataset(\n",
    "        path='D:/Experiment/datasets/OLID/train.tsv',\n",
    "        # path='D:/Experiment/datasets/EXIST2021/train.tsv',\n",
    "        format='tsv',\n",
    "        fields=train_fields,\n",
    "        skip_header=True  # 是否跳过文件的第一行\n",
    "    )\n",
    "    test_fields = [(None, None), ('tweet', TEXT), ('label', LABEL)]\n",
    "    # test_fields = [(None, None), (None, None), (None, None), (None, None), ('text', TEXT), ('task1', LABEL)]\n",
    "    test_data = data.TabularDataset(\n",
    "        path='D:/Experiment/datasets/OLID/testA.tsv',\n",
    "        # path='D:/Experiment/datasets/EXIST2021/test.tsv',\n",
    "        format='tsv',\n",
    "        fields=test_fields,\n",
    "        skip_header=True  # 是否跳过文件的第一行\n",
    "    )\n",
    "    return train_data, test_data, TEXT, LABEL\n",
    "\n",
    "train_data, test_data, TEXT, LABEL = DataLoader()\n",
    "\n",
    "vectors = Vectors(name='glove.6B.300d.txt', cache=processing.EMBEDDING_PATH)\n",
    "\n",
    "TEXT.build_vocab(train_data,  # 建词表是用训练集建，不要用验证集和测试集\n",
    "                 max_size=400000,  # 单词表容量\n",
    "                 vectors=vectors,  # 还有'glove.840B.300d'已经很多可以选\n",
    "                 unk_init=torch.Tensor.normal_  # 初始化train_data中不存在预训练词向量词表中的单词\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embed_size, kernel_sizes, nums_channels, dropout = 300, [3, 4, 5], [100, 100, 100], 0.5\n",
    "model = textCNN(len(TEXT.vocab), embed_size, kernel_sizes, nums_channels, dropout)\n",
    "model.to(DEVICE)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) in (nn.Linear, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "model.apply(init_weights);\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "# print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(300)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, test_data), batch_size=64, sort_within_batch=True, sort_key=lambda x: len(x.tweet), device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_iter, optimizer, loss, epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_sample = 0\n",
    "    correct = 0\n",
    "    for batch in tqdm(train_iter, desc=f\"Training Epoch {epoch}\", colour='red'):\n",
    "        optimizer.zero_grad()\n",
    "        text, text_len = batch.tweet\n",
    "        label = batch.subtask_a\n",
    "        # text, text_len = batch.text\n",
    "        # label = batch.task1\n",
    "        output = model(text)\n",
    "        pred_y = torch.argmax(output, dim=1)\n",
    "        correct += torch.sum(pred_y == label)\n",
    "        l = loss(output, label)\n",
    "        l.backward()\n",
    "        epoch_loss += l.item()\n",
    "        num_sample += len(batch)\n",
    "        optimizer.step()\n",
    "    print(\n",
    "        f'\\tTrain Loss: {epoch_loss / num_sample:.3f} | Train Acc: {correct.float() / num_sample* 100:.2f}%')\n",
    "\n",
    "\n",
    "def test(model, test_iter):\n",
    "    true_y, pred_y = [], []\n",
    "    for batch in tqdm(test_iter, desc=f\"Testing\", colour='green'):\n",
    "        text, text_len = batch.tweet\n",
    "        label = batch.label\n",
    "        # text, text_len = batch.text\n",
    "        # label = batch.task1\n",
    "        with torch.no_grad():\n",
    "            output = model(text)\n",
    "            pred_y.extend(output.argmax(dim=1).tolist())\n",
    "            true_y.extend(label.tolist())\n",
    "    print(metrics.confusion_matrix(true_y, pred_y))\n",
    "    print(metrics.classification_report(true_y, pred_y))\n",
    "    print(f'Acc : {metrics.accuracy_score(true_y, pred_y)}\\t F1: {metrics.f1_score(true_y, pred_y, average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:02<00:00, 77.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.011 | Train Acc: 63.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 482.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[540  80]\n",
      " [161  79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82       620\n",
      "           1       0.50      0.33      0.40       240\n",
      "\n",
      "    accuracy                           0.72       860\n",
      "   macro avg       0.63      0.60      0.61       860\n",
      "weighted avg       0.69      0.72      0.70       860\n",
      "\n",
      "Acc : 0.7197674418604652\t F1: 0.6067762138123507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 116.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.009 | Train Acc: 71.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 466.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[547  73]\n",
      " [147  93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       620\n",
      "           1       0.56      0.39      0.46       240\n",
      "\n",
      "    accuracy                           0.74       860\n",
      "   macro avg       0.67      0.63      0.65       860\n",
      "weighted avg       0.72      0.74      0.73       860\n",
      "\n",
      "Acc : 0.7441860465116279\t F1: 0.6453501885717284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.008 | Train Acc: 74.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 482.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[577  43]\n",
      " [149  91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.86       620\n",
      "           1       0.68      0.38      0.49       240\n",
      "\n",
      "    accuracy                           0.78       860\n",
      "   macro avg       0.74      0.65      0.67       860\n",
      "weighted avg       0.76      0.78      0.75       860\n",
      "\n",
      "Acc : 0.7767441860465116\t F1: 0.6719930711714647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.008 | Train Acc: 77.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 482.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[553  67]\n",
      " [128 112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       620\n",
      "           1       0.63      0.47      0.53       240\n",
      "\n",
      "    accuracy                           0.77       860\n",
      "   macro avg       0.72      0.68      0.69       860\n",
      "weighted avg       0.76      0.77      0.76       860\n",
      "\n",
      "Acc : 0.7732558139534884\t F1: 0.6923607505884037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.007 | Train Acc: 79.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 466.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[578  42]\n",
      " [136 104]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.87       620\n",
      "           1       0.71      0.43      0.54       240\n",
      "\n",
      "    accuracy                           0.79       860\n",
      "   macro avg       0.76      0.68      0.70       860\n",
      "weighted avg       0.78      0.79      0.78       860\n",
      "\n",
      "Acc : 0.7930232558139535\t F1: 0.7027134101343111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.007 | Train Acc: 81.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 482.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[586  34]\n",
      " [129 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       620\n",
      "           1       0.77      0.46      0.58       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.79      0.70      0.73       860\n",
      "weighted avg       0.80      0.81      0.79       860\n",
      "\n",
      "Acc : 0.8104651162790698\t F1: 0.7272629991731117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.006 | Train Acc: 82.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 482.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[572  48]\n",
      " [122 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       620\n",
      "           1       0.71      0.49      0.58       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.77      0.71      0.73       860\n",
      "weighted avg       0.79      0.80      0.79       860\n",
      "\n",
      "Acc : 0.8023255813953488\t F1: 0.7259524184417903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.006 | Train Acc: 83.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 482.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[577  43]\n",
      " [121 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       620\n",
      "           1       0.73      0.50      0.59       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.78      0.71      0.73       860\n",
      "weighted avg       0.80      0.81      0.80       860\n",
      "\n",
      "Acc : 0.8093023255813954\t F1: 0.7338044225005473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 119.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.006 | Train Acc: 84.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 466.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[574  46]\n",
      " [116 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       620\n",
      "           1       0.73      0.52      0.60       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.78      0.72      0.74       860\n",
      "weighted avg       0.80      0.81      0.80       860\n",
      "\n",
      "Acc : 0.8116279069767441\t F1: 0.7406069633215415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.005 | Train Acc: 86.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 466.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[582  38]\n",
      " [115 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88       620\n",
      "           1       0.77      0.52      0.62       240\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.80      0.73      0.75       860\n",
      "weighted avg       0.82      0.82      0.81       860\n",
      "\n",
      "Acc : 0.8220930232558139\t F1: 0.7520871369060067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.005 | Train Acc: 86.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 466.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[569  51]\n",
      " [118 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       620\n",
      "           1       0.71      0.51      0.59       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.77      0.71      0.73       860\n",
      "weighted avg       0.79      0.80      0.79       860\n",
      "\n",
      "Acc : 0.8034883720930233\t F1: 0.7307476412166931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 116.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.005 | Train Acc: 88.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 466.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[588  32]\n",
      " [134 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       620\n",
      "           1       0.77      0.44      0.56       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.79      0.70      0.72       860\n",
      "weighted avg       0.80      0.81      0.79       860\n",
      "\n",
      "Acc : 0.8069767441860465\t F1: 0.7185752923457841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 115.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.004 | Train Acc: 88.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 499.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[573  47]\n",
      " [116 124]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.88       620\n",
      "           1       0.73      0.52      0.60       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.78      0.72      0.74       860\n",
      "weighted avg       0.80      0.81      0.80       860\n",
      "\n",
      "Acc : 0.8104651162790698\t F1: 0.7394418948734105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 115.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.004 | Train Acc: 90.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 466.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[580  40]\n",
      " [121 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       620\n",
      "           1       0.75      0.50      0.60       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.79      0.72      0.74       860\n",
      "weighted avg       0.81      0.81      0.80       860\n",
      "\n",
      "Acc : 0.8127906976744186\t F1: 0.7373069312190393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 116.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.004 | Train Acc: 91.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 466.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[578  42]\n",
      " [118 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88       620\n",
      "           1       0.74      0.51      0.60       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.79      0.72      0.74       860\n",
      "weighted avg       0.81      0.81      0.80       860\n",
      "\n",
      "Acc : 0.813953488372093\t F1: 0.7411899244635709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 92.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 451.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[584  36]\n",
      " [111 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       620\n",
      "           1       0.78      0.54      0.64       240\n",
      "\n",
      "    accuracy                           0.83       860\n",
      "   macro avg       0.81      0.74      0.76       860\n",
      "weighted avg       0.82      0.83      0.82       860\n",
      "\n",
      "Acc : 0.8290697674418605\t F1: 0.7626249823968455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 92.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 482.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[570  50]\n",
      " [109 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       620\n",
      "           1       0.72      0.55      0.62       240\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.78      0.73      0.75       860\n",
      "weighted avg       0.81      0.82      0.81       860\n",
      "\n",
      "Acc : 0.8151162790697675\t F1: 0.749962971699407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 93.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 473.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[586  34]\n",
      " [112 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       620\n",
      "           1       0.79      0.53      0.64       240\n",
      "\n",
      "    accuracy                           0.83       860\n",
      "   macro avg       0.81      0.74      0.76       860\n",
      "weighted avg       0.83      0.83      0.82       860\n",
      "\n",
      "Acc : 0.8302325581395349\t F1: 0.7630210102748776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 94.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 437.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[555  65]\n",
      " [113 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       620\n",
      "           1       0.66      0.53      0.59       240\n",
      "\n",
      "    accuracy                           0.79       860\n",
      "   macro avg       0.75      0.71      0.72       860\n",
      "weighted avg       0.78      0.79      0.79       860\n",
      "\n",
      "Acc : 0.7930232558139535\t F1: 0.724882102599494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:01<00:00, 118.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 94.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 499.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[570  50]\n",
      " [117 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       620\n",
      "           1       0.71      0.51      0.60       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.77      0.72      0.73       860\n",
      "weighted avg       0.80      0.81      0.80       860\n",
      "\n",
      "Acc : 0.8058139534883721\t F1: 0.7339340596638328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.0001, 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(model, train_iter, optimizer, loss, epoch)\n",
    "    test(model, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bbee185f428494c0f3f4eb26ca27cba894eb4f3d4a4ff826385edccebf850a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
