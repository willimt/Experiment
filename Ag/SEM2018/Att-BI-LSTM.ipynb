{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.legacy import data\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from d2l import torch as d2l\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "sys.path.append(\"D:/Experiment\")\n",
    "from tqdm import tqdm\n",
    "from MyKu import training\n",
    "from MyKu import processing\n",
    "from torchtext.vocab import Vectors\n",
    "from spacy.lang.en import English\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processing.create_OLID()\n",
    "# processing.set_olid_train_data(processing.ORIGIN_DATASET_PATH + '/OLID')\n",
    "# processing.set_olid_testA_data(processing.ORIGIN_DATASET_PATH + '/OLID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train_data = processing.get_OLID_train_data(processing.OLID_DATASET + '/train.tsv')\n",
    "# test_data = processing.get_OLID_testA_data(\n",
    "#     processing.OLID_DATASET + '/testA.tsv', processing.OLID_DATASET + '/labels-levela.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spacy_en = English()\n",
    "\n",
    "def tokenizer(text):  # create a tokenizer function\n",
    "    \"\"\"\n",
    "    定义分词操作\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "def DataLoader():\n",
    "    def tokenize(x): return x.split()\n",
    "\n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, include_lengths=True, fix_length=40)\n",
    "    LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "    # 假如train.csv文件并不是只有两列，比如1、3列是review和polarity，2列是我们不需要的数据，\n",
    "    # 那么就要添加一个全是None的元组， fields列表存储的Field的顺序必须和csv文件中每一列的顺序对应，\n",
    "\n",
    "    train_fields = [(None, None), ('tweet', TEXT), ('subtask_a', LABEL)]\n",
    "    # train_fields = [(None, None), (None, None), (None, None), (None, None), ('text', TEXT), ('task1', LABEL)]\n",
    "    train_data= data.TabularDataset(\n",
    "    path='D:/Experiment/datasets/OLID/train.tsv',\n",
    "    # path='D:/Experiment/datasets/EXIST2021/train.tsv',\n",
    "    format='tsv',\n",
    "    fields=train_fields,\n",
    "    skip_header=True  # 是否跳过文件的第一行\n",
    "    )\n",
    "    test_fields = [(None, None), ('tweet', TEXT), ('label', LABEL)]\n",
    "    # test_fields = [(None, None), (None, None), (None, None), (None, None), ('text', TEXT), ('task1', LABEL)]\n",
    "    test_data= data.TabularDataset(\n",
    "    path='D:/Experiment/datasets/OLID/testA.tsv',\n",
    "    # path='D:/Experiment/datasets/EXIST2021/test.tsv',\n",
    "    format='tsv',\n",
    "        fields=test_fields,\n",
    "    skip_header=True  # 是否跳过文件的第一行\n",
    "    )\n",
    "    return train_data, test_data, TEXT, LABEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data, TEXT, LABEL = DataLoader()\n",
    "# x1, x2 = 1, 1\n",
    "# for index in train_data:\n",
    "#     index.task1 = 1 if index.task1 == 'sexist' else 0\n",
    "\n",
    "# for index in test_data:\n",
    "#     index.task1 = 1 if index.task1 == 'sexist' else 0\n",
    "\n",
    "# temp_examples = []\n",
    "# for index in train_data.examples:\n",
    "#     if len(index.text) == 0:\n",
    "#         continue\n",
    "#     if x1 > 3437:\n",
    "#         break\n",
    "#     else:\n",
    "#         x1 += 1\n",
    "#     temp_examples.append(index)\n",
    "# train_data.examples = temp_examples\n",
    "# temp_examples = []\n",
    "# for index in test_data.examples:\n",
    "#     if len(index.text) == 0:\n",
    "#         continue\n",
    "#     if x2 > 1000:\n",
    "#         break\n",
    "#     else:\n",
    "#         x2 += 1\n",
    "#     temp_examples.append(index)\n",
    "# test_data.examples = temp_examples\n",
    "\n",
    "vectors = Vectors(name='glove.6B.300d.txt', cache=processing.EMBEDDING_PATH)\n",
    "\n",
    "TEXT.build_vocab(train_data,  # 建词表是用训练集建，不要用验证集和测试集\n",
    "                  max_size=400000, # 单词表容量\n",
    "                  vectors=vectors, # 还有'glove.840B.300d'已经很多可以选\n",
    "                  unk_init=torch.Tensor.normal_ # 初始化train_data中不存在预训练词向量词表中的单词\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from operator import truediv\n",
    "\n",
    "# BiLSTM + Attention \n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, n_class, bidirectional, dropout, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = nn.LSTM(\n",
    "            embed_size, num_hiddens, num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.n_class = n_class  # 类别数\n",
    "        self.bidirectional = bidirectional  # 控制是否双向LSTM\n",
    "        if self.bidirectional:\n",
    "            self.decoder1 = nn.Linear(num_hiddens * 2, num_hiddens)\n",
    "            self.decoder2 = nn.Linear(num_hiddens, n_class)\n",
    "        else:\n",
    "            self.decoder1 = nn.Linear(num_hiddens * 2, num_hiddens)\n",
    "            self.decoder2 = nn.Linear(num_hiddens, n_class)\n",
    "        self.weight_W = nn.Parameter(torch.Tensor(2 * num_hiddens, 2 * num_hiddens))\n",
    "        self.weight_proj = nn.Parameter(torch.Tensor(2 * num_hiddens, 1))\n",
    "        self.t = nn.Parameter(torch.Tensor(num_hiddens, 2))\n",
    "        nn.init.uniform_(self.weight_W, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.weight_proj, -0.1, 0.1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        # print(embeddings.shape)\n",
    "        self.encoder.flatten_parameters()\n",
    "        outputs, _ = self.encoder(embeddings.permute(1, 0, 2))\n",
    "        # print(outputs.shape)\n",
    "        u = torch.tanh(torch.matmul(outputs, self.weight_W))\n",
    "        # print(u.shape)\n",
    "        att = torch.matmul(u, self.weight_proj)\n",
    "        att_score = F.softmax(att, dim=1)\n",
    "        # print(att_score.shape)\n",
    "        score_x = outputs * att_score\n",
    "        encoding = torch.sum(score_x, dim=1)\n",
    "        # encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
    "        outs = self.decoder1(encoding)\n",
    "        outs = self.decoder2(outs)\n",
    "        # print(outs.shape)\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.zeros([2, 10])\n",
    "ss = torch.ones(10)\n",
    "s = ss.view(1, 10)\n",
    "res = tt + s\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiRNN(\n",
       "  (embedding): Embedding(20148, 300)\n",
       "  (encoder): LSTM(300, 200, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (decoder1): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (decoder2): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.ones((4, 6), dtype=torch.long).to(device=DEVICE)\n",
    "model = BiRNN(len(TEXT.vocab), 300, 200, 1, 2, True, 0.5)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "# print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(300)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, test_data), batch_size=64, sort_within_batch=True, sort_key=lambda x : len(x.tweet), device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_iter, optimizer, loss, epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_sample = 0\n",
    "    correct = 0\n",
    "    for batch in tqdm(train_iter, desc=f\"Training Epoch {epoch}\", colour='red'):\n",
    "        optimizer.zero_grad()\n",
    "        text, text_len = batch.tweet\n",
    "        label = batch.subtask_a\n",
    "        # text, text_len = batch.text\n",
    "        # label = batch.task1\n",
    "        output = model(text)\n",
    "        pred_y = torch.argmax(output, dim=1)\n",
    "        correct += torch.sum(pred_y == label)\n",
    "        l = loss(output, label)\n",
    "        l.backward()\n",
    "        epoch_loss += l.item()\n",
    "        num_sample += len(batch)\n",
    "        optimizer.step()\n",
    "    print(\n",
    "        f'\\tTrain Loss: {epoch_loss / num_sample:.3f} | Train Acc: {correct.float() / num_sample* 100:.2f}%')\n",
    "\n",
    "\n",
    "def test(model, test_iter):\n",
    "    true_y, pred_y = [], []\n",
    "    for batch in tqdm(test_iter, desc=f\"Testing\", colour='green'):\n",
    "        text, text_len = batch.tweet\n",
    "        label = batch.label\n",
    "        # text, text_len = batch.text\n",
    "        # label = batch.task1\n",
    "        with torch.no_grad():\n",
    "            output = model(text)\n",
    "            pred_y.extend(output.argmax(dim=1).tolist())\n",
    "            true_y.extend(label.tolist())\n",
    "    print(metrics.confusion_matrix(true_y, pred_y))\n",
    "    print(metrics.classification_report(true_y, pred_y))\n",
    "    print(f'Acc : {metrics.accuracy_score(true_y, pred_y)}\\t F1: {metrics.f1_score(true_y, pred_y, average=\"macro\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 60.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.009 | Train Acc: 68.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 191.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[590  30]\n",
      " [134 106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.88       620\n",
      "           1       0.78      0.44      0.56       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.80      0.70      0.72       860\n",
      "weighted avg       0.81      0.81      0.79       860\n",
      "\n",
      "Acc : 0.8093023255813954\t F1: 0.7209029888551166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 66.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.007 | Train Acc: 77.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 208.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[583  37]\n",
      " [114 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       620\n",
      "           1       0.77      0.53      0.63       240\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.80      0.73      0.76       860\n",
      "weighted avg       0.82      0.82      0.81       860\n",
      "\n",
      "Acc : 0.8244186046511628\t F1: 0.7553278279268433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 66.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.007 | Train Acc: 79.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 194.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[581  39]\n",
      " [109 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       620\n",
      "           1       0.77      0.55      0.64       240\n",
      "\n",
      "    accuracy                           0.83       860\n",
      "   macro avg       0.81      0.74      0.76       860\n",
      "weighted avg       0.82      0.83      0.82       860\n",
      "\n",
      "Acc : 0.827906976744186\t F1: 0.7630236455036306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 68.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.007 | Train Acc: 80.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 215.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[569  51]\n",
      " [ 93 147]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       620\n",
      "           1       0.74      0.61      0.67       240\n",
      "\n",
      "    accuracy                           0.83       860\n",
      "   macro avg       0.80      0.77      0.78       860\n",
      "weighted avg       0.83      0.83      0.83       860\n",
      "\n",
      "Acc : 0.8325581395348837\t F1: 0.7794541918663048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 67.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.006 | Train Acc: 81.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 218.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[575  45]\n",
      " [101 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89       620\n",
      "           1       0.76      0.58      0.66       240\n",
      "\n",
      "    accuracy                           0.83       860\n",
      "   macro avg       0.80      0.75      0.77       860\n",
      "weighted avg       0.82      0.83      0.82       860\n",
      "\n",
      "Acc : 0.8302325581395349\t F1: 0.771503028185418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 68.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.006 | Train Acc: 82.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 222.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[564  56]\n",
      " [ 89 151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       620\n",
      "           1       0.73      0.63      0.68       240\n",
      "\n",
      "    accuracy                           0.83       860\n",
      "   macro avg       0.80      0.77      0.78       860\n",
      "weighted avg       0.83      0.83      0.83       860\n",
      "\n",
      "Acc : 0.8313953488372093\t F1: 0.7808555245672029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 68.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.005 | Train Acc: 84.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 229.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[573  47]\n",
      " [ 94 146]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       620\n",
      "           1       0.76      0.61      0.67       240\n",
      "\n",
      "    accuracy                           0.84       860\n",
      "   macro avg       0.81      0.77      0.78       860\n",
      "weighted avg       0.83      0.84      0.83       860\n",
      "\n",
      "Acc : 0.836046511627907\t F1: 0.7824038932583968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 63.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.005 | Train Acc: 86.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 194.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[583  37]\n",
      " [106 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       620\n",
      "           1       0.78      0.56      0.65       240\n",
      "\n",
      "    accuracy                           0.83       860\n",
      "   macro avg       0.81      0.75      0.77       860\n",
      "weighted avg       0.83      0.83      0.82       860\n",
      "\n",
      "Acc : 0.8337209302325581\t F1: 0.7714122145208449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 63.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.004 | Train Acc: 88.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 208.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[564  56]\n",
      " [ 96 144]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       620\n",
      "           1       0.72      0.60      0.65       240\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.79      0.75      0.77       860\n",
      "weighted avg       0.82      0.82      0.82       860\n",
      "\n",
      "Acc : 0.8232558139534883\t F1: 0.7678977272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 63.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.004 | Train Acc: 90.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 205.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[556  64]\n",
      " [ 92 148]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       620\n",
      "           1       0.70      0.62      0.65       240\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.78      0.76      0.77       860\n",
      "weighted avg       0.81      0.82      0.81       860\n",
      "\n",
      "Acc : 0.8186046511627907\t F1: 0.7659194327349879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 66.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 91.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 199.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[564  56]\n",
      " [102 138]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       620\n",
      "           1       0.71      0.57      0.64       240\n",
      "\n",
      "    accuracy                           0.82       860\n",
      "   macro avg       0.78      0.74      0.76       860\n",
      "weighted avg       0.81      0.82      0.81       860\n",
      "\n",
      "Acc : 0.8162790697674419\t F1: 0.7565415570733385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 67.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 93.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 222.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[568  52]\n",
      " [112 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.87       620\n",
      "           1       0.71      0.53      0.61       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.77      0.72      0.74       860\n",
      "weighted avg       0.80      0.81      0.80       860\n",
      "\n",
      "Acc : 0.8093023255813954\t F1: 0.7416849816849818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 67.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.002 | Train Acc: 94.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 186.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[566  54]\n",
      " [113 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       620\n",
      "           1       0.70      0.53      0.60       240\n",
      "\n",
      "    accuracy                           0.81       860\n",
      "   macro avg       0.77      0.72      0.74       860\n",
      "weighted avg       0.80      0.81      0.80       860\n",
      "\n",
      "Acc : 0.8058139534883721\t F1: 0.7373824922880564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 65.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.002 | Train Acc: 95.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 211.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[562  58]\n",
      " [114 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       620\n",
      "           1       0.68      0.53      0.59       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.76      0.72      0.73       860\n",
      "weighted avg       0.79      0.80      0.79       860\n",
      "\n",
      "Acc : 0.8\t F1: 0.7308117866293967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 65.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 96.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 199.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[554  66]\n",
      " [109 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       620\n",
      "           1       0.66      0.55      0.60       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.75      0.72      0.73       860\n",
      "weighted avg       0.79      0.80      0.79       860\n",
      "\n",
      "Acc : 0.7965116279069767\t F1: 0.7315716347019909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 65.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 97.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 197.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[550  70]\n",
      " [111 129]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       620\n",
      "           1       0.65      0.54      0.59       240\n",
      "\n",
      "    accuracy                           0.79       860\n",
      "   macro avg       0.74      0.71      0.72       860\n",
      "weighted avg       0.78      0.79      0.78       860\n",
      "\n",
      "Acc : 0.7895348837209303\t F1: 0.7232017270106817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 62.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 97.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 181.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[561  59]\n",
      " [121 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       620\n",
      "           1       0.67      0.50      0.57       240\n",
      "\n",
      "    accuracy                           0.79       860\n",
      "   macro avg       0.75      0.70      0.72       860\n",
      "weighted avg       0.78      0.79      0.78       860\n",
      "\n",
      "Acc : 0.7906976744186046\t F1: 0.7155645712521773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 62.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 98.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 202.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[556  64]\n",
      " [117 123]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       620\n",
      "           1       0.66      0.51      0.58       240\n",
      "\n",
      "    accuracy                           0.79       860\n",
      "   macro avg       0.74      0.70      0.72       860\n",
      "weighted avg       0.78      0.79      0.78       860\n",
      "\n",
      "Acc : 0.7895348837209303\t F1: 0.7180639400410425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 65.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 98.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 205.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[573  47]\n",
      " [122 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       620\n",
      "           1       0.72      0.49      0.58       240\n",
      "\n",
      "    accuracy                           0.80       860\n",
      "   macro avg       0.77      0.71      0.73       860\n",
      "weighted avg       0.79      0.80      0.79       860\n",
      "\n",
      "Acc : 0.8034883720930233\t F1: 0.7270994695582782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|\u001b[31m██████████\u001b[0m| 207/207 [00:03<00:00, 67.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 98.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 14/14 [00:00<00:00, 215.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[540  80]\n",
      " [112 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       620\n",
      "           1       0.62      0.53      0.57       240\n",
      "\n",
      "    accuracy                           0.78       860\n",
      "   macro avg       0.72      0.70      0.71       860\n",
      "weighted avg       0.77      0.78      0.77       860\n",
      "\n",
      "Acc : 0.7767441860465116\t F1: 0.7102425876010782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.0001, 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(model, train_iter, optimizer, loss, epoch)\n",
    "    test(model, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bbee185f428494c0f3f4eb26ca27cba894eb4f3d4a4ff826385edccebf850a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
