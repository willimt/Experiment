{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.legacy import data\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from d2l import torch as d2l\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "sys.path.append(\"D:/Experiment\")\n",
    "from tqdm import tqdm\n",
    "from MyKu import training\n",
    "from MyKu import processing\n",
    "from torchtext.vocab import Vectors\n",
    "from spacy.lang.en import English\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processing.create_OLID()\n",
    "# processing.set_olid_train_data(processing.ORIGIN_DATASET_PATH + '/OLID')\n",
    "# processing.set_olid_testA_data(processing.ORIGIN_DATASET_PATH + '/OLID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):  # create a tokenizer function\n",
    "    \"\"\"\n",
    "    定义分词操作\n",
    "    \"\"\"\n",
    "    return processing.Pre_processing_tweets().tokenize_process(text)\n",
    "\n",
    "\n",
    "def DataLoader():\n",
    "\n",
    "    TEXT = data.Field(sequential=True, tokenize=tokenizer,\n",
    "                      lower=True, include_lengths=True, fix_length=20)\n",
    "    LABEL = data.Field(sequential=False, use_vocab=False)\n",
    "    # 假如train.csv文件并不是只有两列，比如1、3列是review和polarity，2列是我们不需要的数据，\n",
    "    # 那么就要添加一个全是None的元组， fields列表存储的Field的顺序必须和csv文件中每一列的顺序对应，\n",
    "\n",
    "    train_fields = [(None, None), ('label', LABEL),  ('tweet', TEXT)]\n",
    "    # train_fields = [(None, None), (None, None), (None, None), (None, None), ('text', TEXT), ('task1', LABEL)]\n",
    "    train_data = data.TabularDataset(\n",
    "        path='D:/Experiment/datasets/SEM2018/train.tsv',\n",
    "        # path='D:/Experiment/datasets/EXIST2021/train.tsv',\n",
    "        format='tsv',\n",
    "        fields=train_fields,\n",
    "        skip_header=True  # 是否跳过文件的第一行\n",
    "    )\n",
    "    test_fields = [(None, None), ('label', LABEL),  ('tweet', TEXT)]\n",
    "    # test_fields = [(None, None), (None, None), (None, None), (None, None), ('text', TEXT), ('task1', LABEL)]\n",
    "    test_data = data.TabularDataset(\n",
    "        path='D:/Experiment/datasets/SEM2018/test.tsv',\n",
    "        # path='D:/Experiment/datasets/EXIST2021/test.tsv',\n",
    "        format='tsv',\n",
    "        fields=test_fields,\n",
    "        skip_header=True  # 是否跳过文件的第一行\n",
    "    )\n",
    "    return train_data, test_data, TEXT, LABEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data, TEXT, LABEL = DataLoader()\n",
    "\n",
    "\n",
    "vectors = Vectors(name='glove.6B.300d.txt', cache=processing.EMBEDDING_PATH)\n",
    "\n",
    "TEXT.build_vocab(train_data,  # 建词表是用训练集建，不要用验证集和测试集\n",
    "                  max_size=400000, # 单词表容量\n",
    "                  vectors=vectors, # 还有'glove.840B.300d'已经很多可以选\n",
    "                  unk_init=torch.Tensor.normal_ # 初始化train_data中不存在预训练词向量词表中的单词\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from operator import truediv\n",
    "\n",
    "# BiLSTM + Attention \n",
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, n_class, bidirectional, dropout, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = nn.LSTM(\n",
    "            embed_size, num_hiddens, num_layers=num_layers, bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.n_class = n_class  # 类别数\n",
    "        self.bidirectional = bidirectional  # 控制是否双向LSTM\n",
    "        if self.bidirectional:\n",
    "            self.decoder1 = nn.Linear(num_hiddens * 2, num_hiddens)\n",
    "            self.decoder2 = nn.Linear(num_hiddens, n_class)\n",
    "        else:\n",
    "            self.decoder1 = nn.Linear(num_hiddens * 2, num_hiddens)\n",
    "            self.decoder2 = nn.Linear(num_hiddens, n_class)\n",
    "        self.weight_W = nn.Parameter(torch.Tensor(2 * num_hiddens, 2 * num_hiddens))\n",
    "        self.weight_proj = nn.Parameter(torch.Tensor(2 * num_hiddens, 1))\n",
    "        self.t = nn.Parameter(torch.Tensor(num_hiddens, 2))\n",
    "        nn.init.uniform_(self.weight_W, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.weight_proj, -0.1, 0.1)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs)\n",
    "        # print(embeddings.shape)\n",
    "        self.encoder.flatten_parameters()\n",
    "        outputs, _ = self.encoder(embeddings.permute(1, 0, 2))\n",
    "        # print(outputs.shape)\n",
    "        u = torch.tanh(torch.matmul(outputs, self.weight_W))\n",
    "        # print(u.shape)\n",
    "        att = torch.matmul(u, self.weight_proj)\n",
    "        att_score = F.softmax(att, dim=1)\n",
    "        # print(att_score.shape)\n",
    "        score_x = outputs * att_score\n",
    "        encoding = torch.sum(score_x, dim=1)\n",
    "        # encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
    "        outs = self.decoder1(encoding)\n",
    "        outs = self.decoder2(outs)\n",
    "        # print(outs.shape)\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BiRNN(\n",
       "  (embedding): Embedding(9199, 300)\n",
       "  (encoder): LSTM(300, 200, batch_first=True, dropout=0.7, bidirectional=True)\n",
       "  (decoder1): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (decoder2): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = torch.ones((4, 6), dtype=torch.long).to(device=DEVICE)\n",
    "model = BiRNN(len(TEXT.vocab), 300, 200, 1, 2, True, 0.7)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "# print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(300)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits(\n",
    "    (train_data, test_data), batch_size=64, sort_within_batch=True, sort_key=lambda x : len(x.tweet), device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_iter, optimizer, loss, epoch):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_sample = 0\n",
    "    correct = 0\n",
    "    for batch in tqdm(train_iter, desc=f\"Training Epoch {epoch}\", colour='red'):\n",
    "        optimizer.zero_grad()\n",
    "        text, text_len = batch.tweet\n",
    "        label = batch.label\n",
    "        # text, text_len = batch.text\n",
    "        # label = batch.task1\n",
    "        output = model(text)\n",
    "        pred_y = torch.argmax(output, dim=1)\n",
    "        correct += torch.sum(pred_y == label)\n",
    "        l = loss(output, label)\n",
    "        l.backward()\n",
    "        epoch_loss += l.item()\n",
    "        num_sample += len(batch)\n",
    "        optimizer.step()\n",
    "    print(\n",
    "        f'\\tTrain Loss: {epoch_loss / num_sample:.3f} | Train Acc: {correct.float() / num_sample* 100:.2f}%')\n",
    "\n",
    "\n",
    "def test(model, test_iter):\n",
    "    true_y, pred_y = [], []\n",
    "    for batch in tqdm(test_iter, desc=f\"Testing\", colour='green'):\n",
    "        text, text_len = batch.tweet\n",
    "        label = batch.label\n",
    "        # text, text_len = batch.text\n",
    "        # label = batch.task1\n",
    "        with torch.no_grad():\n",
    "            output = model(text)\n",
    "            pred_y.extend(output.argmax(dim=1).tolist())\n",
    "            true_y.extend(label.tolist())\n",
    "    print(metrics.confusion_matrix(true_y, pred_y))\n",
    "    print(metrics.classification_report(true_y, pred_y))\n",
    "    print(f'Acc : {metrics.accuracy_score(true_y, pred_y)}\\t F1: {metrics.f1_score(true_y, pred_y, average=\"macro\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 107.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.011 | Train Acc: 51.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 282.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 27 446]\n",
      " [  7 304]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.06      0.11       473\n",
      "           1       0.41      0.98      0.57       311\n",
      "\n",
      "    accuracy                           0.42       784\n",
      "   macro avg       0.60      0.52      0.34       784\n",
      "weighted avg       0.64      0.42      0.29       784\n",
      "\n",
      "Acc : 0.4221938775510204\t F1: 0.33977658678593936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 104.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.011 | Train Acc: 57.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 371.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150 323]\n",
      " [ 49 262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.32      0.45       473\n",
      "           1       0.45      0.84      0.58       311\n",
      "\n",
      "    accuracy                           0.53       784\n",
      "   macro avg       0.60      0.58      0.52       784\n",
      "weighted avg       0.63      0.53      0.50       784\n",
      "\n",
      "Acc : 0.5255102040816326\t F1: 0.515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 110.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.010 | Train Acc: 60.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 360.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[196 277]\n",
      " [ 67 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.41      0.53       473\n",
      "           1       0.47      0.78      0.59       311\n",
      "\n",
      "    accuracy                           0.56       784\n",
      "   macro avg       0.61      0.60      0.56       784\n",
      "weighted avg       0.64      0.56      0.55       784\n",
      "\n",
      "Acc : 0.5612244897959183\t F1: 0.5595735785953178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 104.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.010 | Train Acc: 65.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 319.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[296 177]\n",
      " [107 204]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68       473\n",
      "           1       0.54      0.66      0.59       311\n",
      "\n",
      "    accuracy                           0.64       784\n",
      "   macro avg       0.63      0.64      0.63       784\n",
      "weighted avg       0.66      0.64      0.64       784\n",
      "\n",
      "Acc : 0.6377551020408163\t F1: 0.6326972312402671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 103.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.009 | Train Acc: 69.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 371.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[341 132]\n",
      " [137 174]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72       473\n",
      "           1       0.57      0.56      0.56       311\n",
      "\n",
      "    accuracy                           0.66       784\n",
      "   macro avg       0.64      0.64      0.64       784\n",
      "weighted avg       0.66      0.66      0.66       784\n",
      "\n",
      "Acc : 0.6568877551020408\t F1: 0.6405796508665279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 111.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.009 | Train Acc: 72.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 360.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[350 123]\n",
      " [143 168]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       473\n",
      "           1       0.58      0.54      0.56       311\n",
      "\n",
      "    accuracy                           0.66       784\n",
      "   macro avg       0.64      0.64      0.64       784\n",
      "weighted avg       0.66      0.66      0.66       784\n",
      "\n",
      "Acc : 0.6607142857142857\t F1: 0.6413886080215706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 112.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.008 | Train Acc: 76.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 371.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[370 103]\n",
      " [149 162]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.75       473\n",
      "           1       0.61      0.52      0.56       311\n",
      "\n",
      "    accuracy                           0.68       784\n",
      "   macro avg       0.66      0.65      0.65       784\n",
      "weighted avg       0.67      0.68      0.67       784\n",
      "\n",
      "Acc : 0.6785714285714286\t F1: 0.6542338709677419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 111.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.007 | Train Acc: 79.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 341.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[319 154]\n",
      " [122 189]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.70       473\n",
      "           1       0.55      0.61      0.58       311\n",
      "\n",
      "    accuracy                           0.65       784\n",
      "   macro avg       0.64      0.64      0.64       784\n",
      "weighted avg       0.65      0.65      0.65       784\n",
      "\n",
      "Acc : 0.6479591836734694\t F1: 0.6380061429747255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 111.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.006 | Train Acc: 82.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 341.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[306 167]\n",
      " [104 207]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.69       473\n",
      "           1       0.55      0.67      0.60       311\n",
      "\n",
      "    accuracy                           0.65       784\n",
      "   macro avg       0.65      0.66      0.65       784\n",
      "weighted avg       0.67      0.65      0.66       784\n",
      "\n",
      "Acc : 0.6543367346938775\t F1: 0.6487356473865638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 111.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.005 | Train Acc: 85.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 371.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[331 142]\n",
      " [124 187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71       473\n",
      "           1       0.57      0.60      0.58       311\n",
      "\n",
      "    accuracy                           0.66       784\n",
      "   macro avg       0.65      0.65      0.65       784\n",
      "weighted avg       0.66      0.66      0.66       784\n",
      "\n",
      "Acc : 0.6607142857142857\t F1: 0.6488685344827586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 112.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.005 | Train Acc: 87.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 282.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[280 193]\n",
      " [ 92 219]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66       473\n",
      "           1       0.53      0.70      0.61       311\n",
      "\n",
      "    accuracy                           0.64       784\n",
      "   macro avg       0.64      0.65      0.63       784\n",
      "weighted avg       0.66      0.64      0.64       784\n",
      "\n",
      "Acc : 0.6364795918367347\t F1: 0.6342655110609148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 111.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.004 | Train Acc: 88.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 371.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[318 155]\n",
      " [116 195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70       473\n",
      "           1       0.56      0.63      0.59       311\n",
      "\n",
      "    accuracy                           0.65       784\n",
      "   macro avg       0.64      0.65      0.65       784\n",
      "weighted avg       0.66      0.65      0.66       784\n",
      "\n",
      "Acc : 0.6543367346938775\t F1: 0.6456139590043484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 108.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 92.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 371.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[289 184]\n",
      " [ 95 216]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67       473\n",
      "           1       0.54      0.69      0.61       311\n",
      "\n",
      "    accuracy                           0.64       784\n",
      "   macro avg       0.65      0.65      0.64       784\n",
      "weighted avg       0.67      0.64      0.65       784\n",
      "\n",
      "Acc : 0.6441326530612245\t F1: 0.6410203388328435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 114.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.003 | Train Acc: 93.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 360.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[277 196]\n",
      " [ 74 237]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.59      0.67       473\n",
      "           1       0.55      0.76      0.64       311\n",
      "\n",
      "    accuracy                           0.66       784\n",
      "   macro avg       0.67      0.67      0.65       784\n",
      "weighted avg       0.69      0.66      0.66       784\n",
      "\n",
      "Acc : 0.6556122448979592\t F1: 0.6547134356404636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 109.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.002 | Train Acc: 94.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 309.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[292 181]\n",
      " [102 209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67       473\n",
      "           1       0.54      0.67      0.60       311\n",
      "\n",
      "    accuracy                           0.64       784\n",
      "   macro avg       0.64      0.64      0.63       784\n",
      "weighted avg       0.66      0.64      0.64       784\n",
      "\n",
      "Acc : 0.639030612244898\t F1: 0.6349390473651909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 107.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 96.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 309.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[335 138]\n",
      " [125 186]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72       473\n",
      "           1       0.57      0.60      0.59       311\n",
      "\n",
      "    accuracy                           0.66       784\n",
      "   macro avg       0.65      0.65      0.65       784\n",
      "weighted avg       0.67      0.66      0.67       784\n",
      "\n",
      "Acc : 0.6645408163265306\t F1: 0.6519701918289154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 93.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 97.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 302.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[317 156]\n",
      " [114 197]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       473\n",
      "           1       0.56      0.63      0.59       311\n",
      "\n",
      "    accuracy                           0.66       784\n",
      "   macro avg       0.65      0.65      0.65       784\n",
      "weighted avg       0.67      0.66      0.66       784\n",
      "\n",
      "Acc : 0.6556122448979592\t F1: 0.647350463802111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 93.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 98.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 276.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[291 182]\n",
      " [ 98 213]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68       473\n",
      "           1       0.54      0.68      0.60       311\n",
      "\n",
      "    accuracy                           0.64       784\n",
      "   macro avg       0.64      0.65      0.64       784\n",
      "weighted avg       0.67      0.64      0.65       784\n",
      "\n",
      "Acc : 0.6428571428571429\t F1: 0.6392867236744378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 89.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 97.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 324.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[323 150]\n",
      " [120 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.71       473\n",
      "           1       0.56      0.61      0.59       311\n",
      "\n",
      "    accuracy                           0.66       784\n",
      "   macro avg       0.64      0.65      0.65       784\n",
      "weighted avg       0.66      0.66      0.66       784\n",
      "\n",
      "Acc : 0.6556122448979592\t F1: 0.6455648726123182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20: 100%|\u001b[31m██████████\u001b[0m| 60/60 [00:00<00:00, 100.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.001 | Train Acc: 98.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|\u001b[32m██████████\u001b[0m| 13/13 [00:00<00:00, 382.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[318 155]\n",
      " [114 197]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70       473\n",
      "           1       0.56      0.63      0.59       311\n",
      "\n",
      "    accuracy                           0.66       784\n",
      "   macro avg       0.65      0.65      0.65       784\n",
      "weighted avg       0.67      0.66      0.66       784\n",
      "\n",
      "Acc : 0.6568877551020408\t F1: 0.6485154537803222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.0001, 20\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train(model, train_iter, optimizer, loss, epoch)\n",
    "    test(model, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bbee185f428494c0f3f4eb26ca27cba894eb4f3d4a4ff826385edccebf850a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
