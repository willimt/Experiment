{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from transformers import BertTokenizer\n",
    "from transformers import logging\n",
    "import processing\n",
    "from sklearn import metrics\n",
    "import MyBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 训练准备阶段，设置超参数和全局变量\n",
    "file_name = 'readme.md'\n",
    "batch_size = 16\n",
    "num_epoch = 10  # 训练轮次\n",
    "check_step = 1  # 用以训练中途对模型进行检验：每check_step个epoch进行一次测试和保存模型\n",
    "\n",
    "learning_rate = 1e-5  # 优化器的学习率\n",
    "\n",
    "# 获取训练、测试数据、分类类别总数\n",
    "train_data = processing.get_exist2021_data_temp(type='train', len=3437)\n",
    "test_data = processing.get_exist2021_data_temp(type='test', len=1000)\n",
    "categories = 2\n",
    "\n",
    "train_iter, test_iter = MyBERT.load_bert_data(train_data, test_data, batch_size)\n",
    "\n",
    "#固定写法，可以牢记，cuda代表Gpu\n",
    "# torch.cuda.is_available()可以查看当前Gpu是否可用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载预训练模型，因为这里是英文数据集，需要用在英文上的预训练模型：bert-base-uncased\n",
    "# uncased指该预训练模型对应的词表不区分字母的大小写\n",
    "# 详情可了解：https://huggingface.co/bert-base-uncased\n",
    "pretrained_model_name = 'bert-base-uncased'\n",
    "# 创建模型 BertSST2Model\n",
    "model = MyBERT.MyBertModel(categories, pretrained_model_name)\n",
    "# 固定写法，将模型加载到device上，\n",
    "# 如果是GPU上运行，此时可以观察到GPU的显存增加\n",
    "model.to(device)\n",
    "\n",
    "# 训练过程\n",
    "# Adam是最近较为常用的优化器，详情可查看：https://www.jianshu.com/p/aebcaf8af76e\n",
    "optimizer = Adam(model.parameters(), learning_rate)  # 使用Adam优化器\n",
    "loss = nn.CrossEntropyLoss()  # 使用crossentropy作为二分类任务的损失函数\n",
    "\n",
    "# 记录当前训练时间，用以记录日志和存储\n",
    "timestamp = time.strftime(\"%m_%d_%H_%M\", time.localtime())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(file_name, 'a+')\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    MyBERT.train(model, train_iter,device, optimizer, loss, epoch)\n",
    "    MyBERT.test(model, test_iter, device, epoch, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bbee185f428494c0f3f4eb26ca27cba894eb4f3d4a4ff826385edccebf850a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
