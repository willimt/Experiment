{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from d2l import torch as d2l\n",
    "from torch import nn\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data():\n",
    "    training_data = pd.read_csv('data\\\\EXIST2021_training.tsv', sep='\\t')\n",
    "    train_text, train_label = [], []\n",
    "    for index in range(3437):\n",
    "        items = training_data.iloc[index]\n",
    "        train_text.append(items['text'])\n",
    "        train_label.append(1 if items['task1'] == 'sexist' else 0)\n",
    "    return train_text, train_label\n",
    "\n",
    "def get_test_data():\n",
    "    testing_data = pd.read_csv('data\\\\EXIST2021_test_labeled.tsv', sep='\\t')\n",
    "    test_text, test_label = [], []\n",
    "    for index in range(1000):\n",
    "        item = testing_data.iloc[index]\n",
    "        test_text.append(item['text'])\n",
    "        test_label.append(1 if item['task1'] == 'sexist' else 0)\n",
    "    return test_text, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size, num_steps=280):\n",
    "    train_data = get_train_data()\n",
    "    test_data = get_test_data()\n",
    "    train_tokens = d2l.tokenize(train_data[0], token='word')\n",
    "    test_tokens = d2l.tokenize(test_data[0], token='word')\n",
    "    vocab = d2l.Vocab(train_tokens, min_freq=5)\n",
    "    print(train_tokens[0])\n",
    "    train_features = torch.tensor([d2l.truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in train_tokens])\n",
    "    test_features = torch.tensor([d2l.truncate_pad(\n",
    "        vocab[line], num_steps, vocab['<pad>']) for line in test_tokens])\n",
    "    train_iter = d2l.load_array((train_features, torch.tensor(train_data[1])), batch_size)\n",
    "    test_iter = d2l.load_array((test_features, torch.tensor(test_data[1])), batch_size, is_train=False)\n",
    "    return train_iter, test_iter, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = d2l.TokenEmbedding('glove.42b.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers, bidirectional=True, dropout=0.5)\n",
    "        self.decoder = nn.Linear(num_hiddens * 4, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeddings = self.embedding(inputs.T)\n",
    "        self.encoder.flatten_parameters()\n",
    "        outputs, _ = self.encoder(embeddings)\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
    "        outs = self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['She', 'calls', 'herself', '\"anti-feminazi\"', 'how', 'about', 'shut', 'the', 'fucking', 'up', 'on', 'your', 'vile', 'commentary', 'on', 'an', 'elderly', 'responsible', 'citizen', 'tu', 'sach', 'muuch', 'ghani', 'baawri-bewdi', 'hai', 'bey', 'https://t.co/ZMxTDwsY5D']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "train_iter, test_iter, vocab = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['commentary']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRNN(\n",
       "  (embedding): Embedding(2106, 300)\n",
       "  (encoder): LSTM(300, 128, dropout=0.5, bidirectional=True)\n",
       "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers = 300, 128, 1\n",
    "devices = d2l.try_all_gpus()\n",
    "net = BiRNN(len(vocab), embed_size, num_hiddens, num_layers)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "    if type(m) == nn.LSTM:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_normal_(m._parameters[param])\n",
    "\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2106, 300])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.embedding.weight.data.copy_(embeds)\n",
    "net.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X = torch.tensor([[0.9,0.1],[0.4, 0.6]])\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from d2l import torch as d2l\n",
    "device = d2l.try_gpu()\n",
    "tt = X.to(device)\n",
    "tt = np.argmax(tt.cpu(), axis=1)\n",
    "y =  torch.tensor([1, 1])\n",
    "y = y.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.f1_score(tt.cpu().numpy(), y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([12, 12, 12], [11, 11, 11], [11, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sldd(tokens):\n",
    "    return [12,12,12], [11,11,11]\n",
    "\n",
    "ss = sldd(12)\n",
    "ss + ([11,1,1],)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bbee185f428494c0f3f4eb26ca27cba894eb4f3d4a4ff826385edccebf850a3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
