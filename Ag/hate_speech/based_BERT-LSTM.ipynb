{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from distutils.command.config import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertModel, BertConfig, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from transformers import BertTokenizer\n",
    "from transformers import logging\n",
    "import processing\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"D:/Experiment\")\n",
    "from MyKu import processing\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = processing.get_hate_train_data()\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/vocab.txt (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLEOFError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\urllib3\\connectionpool.py:700\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[39mif\u001b[39;00m is_new_proxy_conn \u001b[39mand\u001b[39;00m http_tunnel_required:\n\u001b[1;32m--> 700\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\urllib3\\connectionpool.py:994\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._prepare_proxy\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    992\u001b[0m     conn\u001b[39m.\u001b[39mtls_in_tls_required \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m conn\u001b[39m.\u001b[39;49mconnect()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\urllib3\\connection.py:364\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtls_in_tls_required:\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect_tls_proxy(hostname, conn)\n\u001b[0;32m    365\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\urllib3\\connection.py:499\u001b[0m, in \u001b[0;36mHTTPSConnection._connect_tls_proxy\u001b[1;34m(self, hostname, conn)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39m# If no cert was provided, use only the default options for server\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39m# certificate validation\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m socket \u001b[39m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    500\u001b[0m     sock\u001b[39m=\u001b[39;49mconn,\n\u001b[0;32m    501\u001b[0m     ca_certs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_certs,\n\u001b[0;32m    502\u001b[0m     ca_cert_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_dir,\n\u001b[0;32m    503\u001b[0m     ca_cert_data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mca_cert_data,\n\u001b[0;32m    504\u001b[0m     server_hostname\u001b[39m=\u001b[39;49mhostname,\n\u001b[0;32m    505\u001b[0m     ssl_context\u001b[39m=\u001b[39;49mssl_context,\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m ssl_context\u001b[39m.\u001b[39mverify_mode \u001b[39m!=\u001b[39m ssl\u001b[39m.\u001b[39mCERT_NONE \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\n\u001b[0;32m    509\u001b[0m     ssl_context, \u001b[39m\"\u001b[39m\u001b[39mcheck_hostname\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    510\u001b[0m ):\n\u001b[0;32m    511\u001b[0m     \u001b[39m# While urllib3 attempts to always turn off hostname matching from\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     \u001b[39m# the TLS library, this cannot always be done. So we check whether\u001b[39;00m\n\u001b[0;32m    513\u001b[0m     \u001b[39m# the TLS Library still thinks it's matching hostnames.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\urllib3\\util\\ssl_.py:453\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     ssl_sock \u001b[39m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n\u001b[0;32m    454\u001b[0m \u001b[39mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\urllib3\\util\\ssl_.py:495\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     \u001b[39mreturn\u001b[39;00m ssl_context\u001b[39m.\u001b[39;49mwrap_socket(sock)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrap_socket\u001b[39m(\u001b[39mself\u001b[39m, sock, server_side\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m                 do_handshake_on_connect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    497\u001b[0m                 server_hostname\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, session\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     \u001b[39m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msslsocket_class\u001b[39m.\u001b[39;49m_create(\n\u001b[0;32m    501\u001b[0m         sock\u001b[39m=\u001b[39;49msock,\n\u001b[0;32m    502\u001b[0m         server_side\u001b[39m=\u001b[39;49mserver_side,\n\u001b[0;32m    503\u001b[0m         do_handshake_on_connect\u001b[39m=\u001b[39;49mdo_handshake_on_connect,\n\u001b[0;32m    504\u001b[0m         suppress_ragged_eofs\u001b[39m=\u001b[39;49msuppress_ragged_eofs,\n\u001b[0;32m    505\u001b[0m         server_hostname\u001b[39m=\u001b[39;49mserver_hostname,\n\u001b[0;32m    506\u001b[0m         context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    507\u001b[0m         session\u001b[39m=\u001b[39;49msession\n\u001b[0;32m    508\u001b[0m     )\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\ssl.py:1040\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1040\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1041\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\ssl.py:1309\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1308\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msettimeout(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1309\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mdo_handshake()\n\u001b[0;32m   1310\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLEOFError\u001b[0m: EOF occurred in violation of protocol (_ssl.c:1131)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\requests\\adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 440\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    441\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    442\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    443\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    444\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    445\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    446\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    447\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    448\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    449\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    450\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    451\u001b[0m     )\n\u001b[0;32m    453\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\urllib3\\connectionpool.py:785\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    783\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 785\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    786\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    787\u001b[0m )\n\u001b[0;32m    788\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/vocab.txt (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Experiment\\Ag\\hate_speech\\based_BERT-LSTM.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Experiment/Ag/hate_speech/based_BERT-LSTM.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     torch\u001b[39m.\u001b[39msave(model, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m'\u001b[39m\u001b[39mmodel.pth\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Experiment/Ag/hate_speech/based_BERT-LSTM.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pretrained_model_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Experiment/Ag/hate_speech/based_BERT-LSTM.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Experiment/Ag/hate_speech/based_BERT-LSTM.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     pretrained_model_name, do_lower_case\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1719\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1718\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1719\u001b[0m         resolved_vocab_files[file_id] \u001b[39m=\u001b[39m cached_path(\n\u001b[0;32m   1720\u001b[0m             file_path,\n\u001b[0;32m   1721\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   1722\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   1723\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1724\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   1725\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   1726\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m   1727\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   1728\u001b[0m         )\n\u001b[0;32m   1730\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m   1731\u001b[0m         \u001b[39mif\u001b[39;00m local_files_only:\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\utils\\hub.py:282\u001b[0m, in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    278\u001b[0m     local_files_only \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[0;32m    281\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[1;32m--> 282\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[0;32m    283\u001b[0m         url_or_filename,\n\u001b[0;32m    284\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    285\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    286\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    287\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    288\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    289\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    290\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[0;32m    293\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m     output_path \u001b[39m=\u001b[39m url_or_filename\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\transformers\\utils\\hub.py:485\u001b[0m, in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m local_files_only:\n\u001b[0;32m    484\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 485\u001b[0m         r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mhead(url, headers\u001b[39m=\u001b[39;49mheaders, allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, proxies\u001b[39m=\u001b[39;49mproxies, timeout\u001b[39m=\u001b[39;49metag_timeout)\n\u001b[0;32m    486\u001b[0m         _raise_for_status(r)\n\u001b[0;32m    487\u001b[0m         etag \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Linked-Etag\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m r\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mETag\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\requests\\api.py:102\u001b[0m, in \u001b[0;36mhead\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a HEAD request.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mhead\u001b[39;49m\u001b[39m'\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\requests\\api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[0;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[0;32m    527\u001b[0m }\n\u001b[0;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\requests\\sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32md:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\requests\\adapters.py:517\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[39mraise\u001b[39;00m ProxyError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mSSLError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /bert-base-uncased/resolve/main/vocab.txt (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1131)')))"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 60\n",
    "\n",
    "\n",
    "def save_pretrained(model, path):\n",
    "    # 保存模型，先利用os模块创建文件夹，后利用torch.save()写入模型文件\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    torch.save(model, os.path.join(path, 'model.pth'))\n",
    "\n",
    "\n",
    "pretrained_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    pretrained_model_name, do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_for_bert(data):\n",
    "    input_ids, attention_masks, labels = [], [], []\n",
    "    for sent, label in data:\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=sent,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            )\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "        labels.append(label)\n",
    "    input_ids = torch.Tensor(input_ids)\n",
    "    attention_masks = torch.Tensor(attention_masks)\n",
    "    # print(attention_masks)\n",
    "    labels = torch.Tensor(labels)\n",
    "    return input_ids, attention_masks, labels\n",
    "\n",
    "\n",
    "\n",
    "train_inputs, train_masks, train_labels = preprocessing_for_bert(train_data)\n",
    "test_inputs, test_masks, test_labels = preprocessing_for_bert(test_data)\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "test_dataset = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "\n",
    "train_iter = DataLoader(train_dataset, sampler=train_sampler, batch_size=32)\n",
    "test_iter = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyBertModel(nn.Module):\n",
    "\n",
    "    def __init__(self, class_size, num_layers, dropout, pretrained_name='bert-base-uncased'):\n",
    "\n",
    "        # 类继承的初始化，固定写法\n",
    "        super(MyBertModel, self).__init__()\n",
    "        # 加载HuggingFace的BertModel\n",
    "        # BertModel的最终输出维度默认为768\n",
    "        # return_dict=True 可以使BertModel的输出具有dict属性，即以 bert_output['last_hidden_state'] 方式调用\n",
    "\n",
    "        config = BertConfig.from_pretrained(pretrained_name)\n",
    "        config.output_attentions = True\n",
    "        config.return_dict = True\n",
    "        self.bert = BertModel.from_pretrained(pretrained_name, config=config)\n",
    "        # 通过一个线性层将[CLS]标签对应的维度：768->class_size\n",
    "        # class_size 在SST-2情感分类任务中设置为：2\n",
    "        self.lstm = nn.LSTM(768, 100, num_layers=num_layers,\n",
    "                            bidirectional=True, dropout=dropout, batch_first=True)\n",
    "        self.weight_W = nn.Parameter(torch.Tensor(768, 768))\n",
    "        self.weight_proj = nn.Parameter(torch.Tensor(768, 768))\n",
    "        # self.U = nn.Parameter(torch.Tensor(MAX_LEN, class_size))\n",
    "        # self.V = nn.Parameter(torch.Tensor(MAX_LEN, class_size))\n",
    "        # self.g = nn.Parameter(torch.Tensor(class_size))\n",
    "        # self.W_f = nn.Parameter(torch.Tensor(2 * MAX_LEN, class_size))\n",
    "        # self.bias = nn.Parameter(torch.Tensor(class_size))\n",
    "        self.decoder1 = nn.Linear(100 * 4, MAX_LEN)\n",
    "        self.decoder2 = nn.Linear(2 * MAX_LEN, class_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        nn.init.uniform_(self.weight_W, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.weight_proj, -0.1, 0.1)\n",
    "        # nn.init.uniform_(self.U, -0.1, 0.1)\n",
    "        # nn.init.uniform_(self.V, -0.1, 0.1)\n",
    "        # nn.init.uniform_(self.g, -0.1, 0.1)\n",
    "        # nn.init.uniform_(self.W_f, -0.1, 0.1)\n",
    "        # nn.init.uniform_(self.bias, -0.1, 0.1)\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(768, 100),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(100, class_size)\n",
    "        # )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 获取DataLoader中已经处理好的输入数据：\n",
    "        # input_ids :tensor类型，shape=batch_size*max_len   max_len为当前batch中的最大句长\n",
    "        # input_tyi :tensor类型，\n",
    "        # input_attn_mask :tensor类型，因为input_ids中存在大量[Pad]填充，attention mask将pad部分值置为0，让模型只关注非pad部分\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state_cls = outputs[0] # last_hidden_state_cls (32, 60, 768)\n",
    "        bert_output, idxs = torch.max(last_hidden_state_cls, dim=2) # bert_output (32, 60)\n",
    "        # print(last_hidden_state_cls.shape)\n",
    "        w = torch.tanh(torch.matmul(last_hidden_state_cls, self.weight_W))  # w torch.Size([32, 60, 768])\n",
    "        self_matching = torch.matmul(w, self.weight_proj)   # w torch.Size([32, 60, 60])\n",
    "        att_score, idxs = torch.max(self_matching, dim=2)   # att_score torch.Size([32, 60])\n",
    "        self.lstm.flatten_parameters()\n",
    "        output_hidden, _ = self.lstm(last_hidden_state_cls) #output_hidden (32, 60, 200)\n",
    "        output = torch.cat((output_hidden[:,0,:], output_hidden[:,-1,:]), dim=1)    # output torch.Size([64, 400])\n",
    "        output = self.decoder1(output)      # output torch.Size([32, 60])\n",
    "        # self_matching_out torch.Size([32, 60])\n",
    "        self_matching_out = att_score.mul(output)\n",
    "        # outs = self.decoder2(self_matching_out)\n",
    "        f = torch.cat((bert_output, self_matching_out), dim=-1)\n",
    "        # outs = torch.softmax(torch.matmul(f, self.W_f) + self.bias, dim=1)\n",
    "        # f = self.relu(f)\n",
    "        outs = self.decoder2(f)\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(epoch=10):\n",
    "    bert_model = MyBertModel(2, 1, 0.5)\n",
    "    bert_model.to(DEVICE)\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = AdamW(\n",
    "        bert_model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        eps = 1e-8\n",
    "    )\n",
    "    total_steps = len(train_iter) * epoch\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    return bert_model, optimizer, scheduler\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_iter, test_iter, optimizer, scheduler, epochs=10, evaluation=None):\n",
    "    for num_epoch in range(epochs):\n",
    "        print(f\"{'Epoch':^7} | {'每40个Batch':^9} | {'训练集 Loss':^12} | {'测试集 Loss':^10} | {'测试集准确率':^9} | {'时间':^9}\")\n",
    "        print(\"-\" * 80)\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_iter):\n",
    "            batch_counts += 1\n",
    "            b_input_ids, b_att_masks, b_labels = tuple(t.to(DEVICE, dtype=torch.int32) for t in batch)\n",
    "            model.zero_grad()\n",
    "            # b_input_ids = b_input_ids.to(dtype=torch.int32)\n",
    "            output = model(b_input_ids, b_att_masks)\n",
    "            # print(output.dtype)\n",
    "            b_input_ids = b_input_ids.to(dtype=torch.int32)\n",
    "            loss = loss_fn(output, b_labels.long())\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            if(step % 40 == 0 and step != 0) or (step == len(train_iter) - 1):\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "                print(f\"{num_epoch + 1:^7} | {step:^10}  | {batch_loss / batch_counts:^14.6f}  | {'-':^12} | {'-':^13} |  {time_elapsed:^9.2f}\")\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "        \n",
    "        avg_train_loss = total_loss / len(train_iter)\n",
    "        print('-' * 80)\n",
    "\n",
    "        if evaluation:\n",
    "            test_loss, test_accuracy, f1_score = evaluate(model, test_iter)\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            print(f\"{num_epoch + 1:^7} | {'-':^10} | {avg_train_loss:^14.6f} | {test_loss:^12.6f} | {test_accuracy:^12.2f} | {f1_score:^12.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\" * 80)\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "def evaluate(model, test_dataloader):\n",
    "    \"\"\"\n",
    "    在每个epoch后验证集上评估model性能\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # 准确率和误差\n",
    "    test_accuracy = []\n",
    "    test_loss = []\n",
    "    pred_y, true_y = [], []\n",
    "    # 验证集上的每个batch\n",
    "    for batch in test_dataloader:\n",
    "        # 放到GPU上\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(\n",
    "            t.to(DEVICE, dtype=torch.int32) for t in batch)\n",
    "        # 计算结果，不计算梯度\n",
    "        with torch.no_grad():\n",
    "            # 放到model里面去跑，返回验证集的ouput就是一行三列的\n",
    "            output = model(b_input_ids, b_attn_mask)\n",
    "        # 计算误差\n",
    "        loss = loss_fn(output, b_labels.long())\n",
    "        test_loss.append(loss.item())\n",
    "        pred = torch.argmax(output, dim=1).flatten()\n",
    "        # get预测结果，这里就是求每行最大的索引咯，然后用flatten打平成一维\n",
    "        # 计算准确率，这个就是俩比较，返回相同的个数, .cpu().numpy()就是把tensor从显卡上取出来然后转化为numpy类型的举证好用方法\n",
    "        # 最后mean因为直接bool形了，也就是如果预测和label一样那就返回1，正好是正确的个数，求平均就是准确率了\n",
    "        accuracy = (pred == b_labels).cpu().numpy().mean() * 100\n",
    "        test_accuracy.append(accuracy)\n",
    "        pred_y.extend(pred.tolist())\n",
    "        true_y.extend(b_labels.tolist())\n",
    "    # print(len(true_y))\n",
    "    # 计算整体的平均正确率和loss\n",
    "    print(metrics.confusion_matrix(true_y, pred_y))\n",
    "    val_loss = np.mean(test_loss)\n",
    "    val_accuracy = np.mean(test_accuracy)\n",
    "    f1_socre = metrics.f1_score(true_y, pred_y, average=\"macro\") * 100\n",
    "\n",
    "    return val_loss, val_accuracy, f1_socre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training and testing:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_model, optimizer, scheduler = initialize_model(2)\n",
    "print(\"Start training and testing:\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  | 每40个Batch |   训练集 Loss   |  测试集 Loss  |  测试集准确率   |    时间    \n",
      "--------------------------------------------------------------------------------\n",
      "   1    |     40      |    0.054593     |      -       |       -       |    15.13  \n",
      "   1    |     80      |    0.086721     |      -       |       -       |    14.28  \n",
      "   1    |    120      |    0.096437     |      -       |       -       |    14.19  \n",
      "   1    |    160      |    0.081535     |      -       |       -       |    14.86  \n",
      "   1    |    200      |    0.087636     |      -       |       -       |    15.01  \n",
      "   1    |    240      |    0.062547     |      -       |       -       |    14.81  \n",
      "   1    |    280      |    0.066267     |      -       |       -       |    15.00  \n",
      "   1    |    320      |    0.059969     |      -       |       -       |    14.92  \n",
      "   1    |    360      |    0.064187     |      -       |       -       |    15.05  \n",
      "   1    |    400      |    0.075416     |      -       |       -       |    14.83  \n",
      "   1    |    440      |    0.077432     |      -       |       -       |    14.19  \n",
      "   1    |    480      |    0.065957     |      -       |       -       |    15.16  \n",
      "   1    |    520      |    0.072558     |      -       |       -       |    13.94  \n",
      "   1    |    560      |    0.073239     |      -       |       -       |    15.37  \n",
      "   1    |    600      |    0.079095     |      -       |       -       |    15.06  \n",
      "   1    |    619      |    0.073082     |      -       |       -       |    6.97   \n",
      "--------------------------------------------------------------------------------\n",
      "[[ 723   92]\n",
      " [  83 4059]]\n",
      "   1    |     -      |    0.073527    |   0.104906   |    96.47     |    93.55     |  243.60  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  | 每40个Batch |   训练集 Loss   |  测试集 Loss  |  测试集准确率   |    时间    \n",
      "--------------------------------------------------------------------------------\n",
      "   2    |     40      |    0.076796     |      -       |       -       |    15.62  \n",
      "   2    |     80      |    0.071028     |      -       |       -       |    29.51  \n",
      "   2    |    120      |    0.075200     |      -       |       -       |    15.26  \n",
      "   2    |    160      |    0.070374     |      -       |       -       |    15.46  \n",
      "   2    |    200      |    0.048059     |      -       |       -       |    15.10  \n",
      "   2    |    240      |    0.065650     |      -       |       -       |    15.17  \n",
      "   2    |    280      |    0.088337     |      -       |       -       |    15.00  \n",
      "   2    |    320      |    0.068440     |      -       |       -       |    15.14  \n",
      "   2    |    360      |    0.088149     |      -       |       -       |    14.97  \n",
      "   2    |    400      |    0.071043     |      -       |       -       |    15.05  \n",
      "   2    |    440      |    0.071177     |      -       |       -       |    15.08  \n",
      "   2    |    480      |    0.072872     |      -       |       -       |    15.23  \n",
      "   2    |    520      |    0.084289     |      -       |       -       |    15.10  \n",
      "   2    |    560      |    0.082077     |      -       |       -       |    15.31  \n",
      "   2    |    600      |    0.076477     |      -       |       -       |    14.98  \n",
      "   2    |    619      |    0.059007     |      -       |       -       |    6.94   \n",
      "--------------------------------------------------------------------------------\n",
      "[[ 723   92]\n",
      " [  83 4059]]\n",
      "   2    |     -      |    0.073543    |   0.104906   |    96.47     |    93.55     |  263.72  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  | 每40个Batch |   训练集 Loss   |  测试集 Loss  |  测试集准确率   |    时间    \n",
      "--------------------------------------------------------------------------------\n",
      "   3    |     40      |    0.063298     |      -       |       -       |    15.18  \n",
      "   3    |     80      |    0.072643     |      -       |       -       |    14.73  \n",
      "   3    |    120      |    0.074910     |      -       |       -       |    14.80  \n",
      "   3    |    160      |    0.069491     |      -       |       -       |    14.83  \n",
      "   3    |    200      |    0.061123     |      -       |       -       |    15.03  \n",
      "   3    |    240      |    0.072503     |      -       |       -       |    14.40  \n",
      "   3    |    280      |    0.078573     |      -       |       -       |    15.09  \n",
      "   3    |    320      |    0.083326     |      -       |       -       |    14.86  \n",
      "   3    |    360      |    0.073935     |      -       |       -       |    14.89  \n",
      "   3    |    400      |    0.078456     |      -       |       -       |    15.08  \n",
      "   3    |    440      |    0.074649     |      -       |       -       |    15.05  \n",
      "   3    |    480      |    0.082407     |      -       |       -       |    14.80  \n",
      "   3    |    520      |    0.056499     |      -       |       -       |    14.90  \n",
      "   3    |    560      |    0.077658     |      -       |       -       |    15.14  \n",
      "   3    |    600      |    0.068706     |      -       |       -       |    14.99  \n",
      "   3    |    619      |    0.052863     |      -       |       -       |    6.94   \n",
      "--------------------------------------------------------------------------------\n",
      "[[ 723   92]\n",
      " [  83 4059]]\n",
      "   3    |     -      |    0.071927    |   0.104906   |    96.47     |    93.55     |  245.47  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train(bert_model, train_iter,\n",
    "      test_iter, optimizer, scheduler, epochs=1, evaluation=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bbee185f428494c0f3f4eb26ca27cba894eb4f3d4a4ff826385edccebf850a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
